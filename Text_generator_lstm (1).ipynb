{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tIfahvefGBXx"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"The mentorship program offers a comprehensive learning experience through a monthly subscription model, with a fee of $X per month.\n",
        "Spanning Y months, the total cost of the program is approximately $X * Y.\n",
        "This program covers a wide array of topics, including fundamentals, essential libraries/tools, data analysis, SQL for analysis, mathematics for learning, algorithms, practical implementation, operations and deployment, and case studies.\n",
        "For those interested in the detailed syllabus, it is available via a provided link.\n",
        "While the curriculum does not include advanced topics, it ensures a thorough understanding of the core concepts.\n",
        "All live sessions are recorded, allowing participants to catch up on any missed content at their convenience.\n",
        "The schedule for these sessions is organized month-by-month and accessible through a shared Google Sheet link.\n",
        "Each session typically lasts around 2 hours and is conducted in English, making it accessible to a broad audience.\n",
        "Participants are informed about upcoming classes through email notifications once they become paid users.\n",
        "This program is designed to be inclusive, welcoming individuals from non-technical backgrounds.\n",
        "Flexibility is a key feature, allowing participants to join at any point during the course.\n",
        "If joining mid-way, participants will have access to all previous lectures upon payment.\n",
        "Tasks provided during the course are meant for self-evaluation, with solutions supplied for personal assessment.\n",
        "Additionally, the program includes case studies to enhance practical understanding.\n",
        "For any queries, participants can reach out via the provided email address.\n",
        "Payments are to be made on the program's official website, following a monthly subscription model.\n",
        "While the entire amount cannot be paid upfront, the subscription is valid for 30 days from the payment date, ensuring participants do not need to wait for the start of a new month.\n",
        "A 7-day refund policy is in place for those who may reconsider their participation after making the payment.\n",
        "In case of payment issues due to location restrictions, the support team can be contacted through email.\n",
        "Post-registration, participants can watch paid videos as long as their subscription is active.\n",
        "Upon completing the full payment, access to the content extends until a specified date, beyond which a new subscription is required.\n",
        "Lifetime access is not provided due to the low course fee.\n",
        "For doubt resolution, a form available in the dashboard can be filled out, prompting the team to arrange a one-on-one doubt clearance session.\n",
        "Late joiners can still address past weeks' doubts by selecting the appropriate option in the doubt clearance form.\n",
        "The criteria for obtaining a certificate include paying the full fee and attempting all course assessments.\n",
        "For those joining late, a link to pay for the previous months' fees will be available in the dashboard after the current month's payment.\n",
        "Placement assistance is also part of the program, encompassing portfolio building sessions, soft skill training, and interactions with industry mentors.\n",
        "However, it is important to note that placement assistance does not equate to a placement guarantee.\n",
        "The focus is on equipping participants with the skills and knowledge needed to enhance their employability.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([faqs])\n"
      ],
      "metadata": {
        "id": "V_oH2Y95GFyR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcUw2WX5GhTf",
        "outputId": "89edbacb-4405-4ec8-d2fb-f2ef46985737"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'to': 3,\n",
              " 'is': 4,\n",
              " 'for': 5,\n",
              " 'participants': 6,\n",
              " 'of': 7,\n",
              " 'and': 8,\n",
              " 'in': 9,\n",
              " 'program': 10,\n",
              " 'be': 11,\n",
              " 'payment': 12,\n",
              " 'subscription': 13,\n",
              " 'can': 14,\n",
              " 'through': 15,\n",
              " 'with': 16,\n",
              " 'month': 17,\n",
              " 'it': 18,\n",
              " 'provided': 19,\n",
              " 'not': 20,\n",
              " 'are': 21,\n",
              " 'on': 22,\n",
              " 'their': 23,\n",
              " 'course': 24,\n",
              " 'fee': 25,\n",
              " 'case': 26,\n",
              " 'those': 27,\n",
              " 'available': 28,\n",
              " 'link': 29,\n",
              " 'all': 30,\n",
              " 'sessions': 31,\n",
              " 'any': 32,\n",
              " 'email': 33,\n",
              " 'paid': 34,\n",
              " 'access': 35,\n",
              " 'doubt': 36,\n",
              " 'placement': 37,\n",
              " 'learning': 38,\n",
              " 'monthly': 39,\n",
              " 'model': 40,\n",
              " 'x': 41,\n",
              " 'y': 42,\n",
              " 'this': 43,\n",
              " 'topics': 44,\n",
              " 'analysis': 45,\n",
              " 'practical': 46,\n",
              " 'studies': 47,\n",
              " 'via': 48,\n",
              " 'while': 49,\n",
              " 'does': 50,\n",
              " 'include': 51,\n",
              " 'understanding': 52,\n",
              " 'allowing': 53,\n",
              " 'content': 54,\n",
              " 'at': 55,\n",
              " 'by': 56,\n",
              " 'accessible': 57,\n",
              " 'session': 58,\n",
              " 'making': 59,\n",
              " 'from': 60,\n",
              " 'during': 61,\n",
              " 'joining': 62,\n",
              " 'will': 63,\n",
              " 'previous': 64,\n",
              " 'upon': 65,\n",
              " 'enhance': 66,\n",
              " 'out': 67,\n",
              " 'address': 68,\n",
              " 'date': 69,\n",
              " 'new': 70,\n",
              " 'after': 71,\n",
              " 'due': 72,\n",
              " 'team': 73,\n",
              " 'as': 74,\n",
              " 'full': 75,\n",
              " 'form': 76,\n",
              " 'dashboard': 77,\n",
              " 'one': 78,\n",
              " 'clearance': 79,\n",
              " 'late': 80,\n",
              " 'assistance': 81,\n",
              " 'mentorship': 82,\n",
              " 'offers': 83,\n",
              " 'comprehensive': 84,\n",
              " 'experience': 85,\n",
              " 'per': 86,\n",
              " 'spanning': 87,\n",
              " 'months': 88,\n",
              " 'total': 89,\n",
              " 'cost': 90,\n",
              " 'approximately': 91,\n",
              " 'covers': 92,\n",
              " 'wide': 93,\n",
              " 'array': 94,\n",
              " 'including': 95,\n",
              " 'fundamentals': 96,\n",
              " 'essential': 97,\n",
              " 'libraries': 98,\n",
              " 'tools': 99,\n",
              " 'data': 100,\n",
              " 'sql': 101,\n",
              " 'mathematics': 102,\n",
              " 'algorithms': 103,\n",
              " 'implementation': 104,\n",
              " 'operations': 105,\n",
              " 'deployment': 106,\n",
              " 'interested': 107,\n",
              " 'detailed': 108,\n",
              " 'syllabus': 109,\n",
              " 'curriculum': 110,\n",
              " 'advanced': 111,\n",
              " 'ensures': 112,\n",
              " 'thorough': 113,\n",
              " 'core': 114,\n",
              " 'concepts': 115,\n",
              " 'live': 116,\n",
              " 'recorded': 117,\n",
              " 'catch': 118,\n",
              " 'up': 119,\n",
              " 'missed': 120,\n",
              " 'convenience': 121,\n",
              " 'schedule': 122,\n",
              " 'these': 123,\n",
              " 'organized': 124,\n",
              " 'shared': 125,\n",
              " 'google': 126,\n",
              " 'sheet': 127,\n",
              " 'each': 128,\n",
              " 'typically': 129,\n",
              " 'lasts': 130,\n",
              " 'around': 131,\n",
              " '2': 132,\n",
              " 'hours': 133,\n",
              " 'conducted': 134,\n",
              " 'english': 135,\n",
              " 'broad': 136,\n",
              " 'audience': 137,\n",
              " 'informed': 138,\n",
              " 'about': 139,\n",
              " 'upcoming': 140,\n",
              " 'classes': 141,\n",
              " 'notifications': 142,\n",
              " 'once': 143,\n",
              " 'they': 144,\n",
              " 'become': 145,\n",
              " 'users': 146,\n",
              " 'designed': 147,\n",
              " 'inclusive': 148,\n",
              " 'welcoming': 149,\n",
              " 'individuals': 150,\n",
              " 'non': 151,\n",
              " 'technical': 152,\n",
              " 'backgrounds': 153,\n",
              " 'flexibility': 154,\n",
              " 'key': 155,\n",
              " 'feature': 156,\n",
              " 'join': 157,\n",
              " 'point': 158,\n",
              " 'if': 159,\n",
              " 'mid': 160,\n",
              " 'way': 161,\n",
              " 'have': 162,\n",
              " 'lectures': 163,\n",
              " 'tasks': 164,\n",
              " 'meant': 165,\n",
              " 'self': 166,\n",
              " 'evaluation': 167,\n",
              " 'solutions': 168,\n",
              " 'supplied': 169,\n",
              " 'personal': 170,\n",
              " 'assessment': 171,\n",
              " 'additionally': 172,\n",
              " 'includes': 173,\n",
              " 'queries': 174,\n",
              " 'reach': 175,\n",
              " 'payments': 176,\n",
              " 'made': 177,\n",
              " \"program's\": 178,\n",
              " 'official': 179,\n",
              " 'website': 180,\n",
              " 'following': 181,\n",
              " 'entire': 182,\n",
              " 'amount': 183,\n",
              " 'cannot': 184,\n",
              " 'upfront': 185,\n",
              " 'valid': 186,\n",
              " '30': 187,\n",
              " 'days': 188,\n",
              " 'ensuring': 189,\n",
              " 'do': 190,\n",
              " 'need': 191,\n",
              " 'wait': 192,\n",
              " 'start': 193,\n",
              " '7': 194,\n",
              " 'day': 195,\n",
              " 'refund': 196,\n",
              " 'policy': 197,\n",
              " 'place': 198,\n",
              " 'who': 199,\n",
              " 'may': 200,\n",
              " 'reconsider': 201,\n",
              " 'participation': 202,\n",
              " 'issues': 203,\n",
              " 'location': 204,\n",
              " 'restrictions': 205,\n",
              " 'support': 206,\n",
              " 'contacted': 207,\n",
              " 'post': 208,\n",
              " 'registration': 209,\n",
              " 'watch': 210,\n",
              " 'videos': 211,\n",
              " 'long': 212,\n",
              " 'active': 213,\n",
              " 'completing': 214,\n",
              " 'extends': 215,\n",
              " 'until': 216,\n",
              " 'specified': 217,\n",
              " 'beyond': 218,\n",
              " 'which': 219,\n",
              " 'required': 220,\n",
              " 'lifetime': 221,\n",
              " 'low': 222,\n",
              " 'resolution': 223,\n",
              " 'filled': 224,\n",
              " 'prompting': 225,\n",
              " 'arrange': 226,\n",
              " 'joiners': 227,\n",
              " 'still': 228,\n",
              " 'past': 229,\n",
              " \"weeks'\": 230,\n",
              " 'doubts': 231,\n",
              " 'selecting': 232,\n",
              " 'appropriate': 233,\n",
              " 'option': 234,\n",
              " 'criteria': 235,\n",
              " 'obtaining': 236,\n",
              " 'certificate': 237,\n",
              " 'paying': 238,\n",
              " 'attempting': 239,\n",
              " 'assessments': 240,\n",
              " 'pay': 241,\n",
              " \"months'\": 242,\n",
              " 'fees': 243,\n",
              " 'current': 244,\n",
              " \"month's\": 245,\n",
              " 'also': 246,\n",
              " 'part': 247,\n",
              " 'encompassing': 248,\n",
              " 'portfolio': 249,\n",
              " 'building': 250,\n",
              " 'soft': 251,\n",
              " 'skill': 252,\n",
              " 'training': 253,\n",
              " 'interactions': 254,\n",
              " 'industry': 255,\n",
              " 'mentors': 256,\n",
              " 'however': 257,\n",
              " 'important': 258,\n",
              " 'note': 259,\n",
              " 'that': 260,\n",
              " 'equate': 261,\n",
              " 'guarantee': 262,\n",
              " 'focus': 263,\n",
              " 'equipping': 264,\n",
              " 'skills': 265,\n",
              " 'knowledge': 266,\n",
              " 'needed': 267,\n",
              " 'employability': 268}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANHSSlBdGdqt",
        "outputId": "a4261a1f-0171-429e-8d64-2927e3fbd6e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "268"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in faqs.split('\\n'):\n",
        "    print(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHd10BR6Gl6e",
        "outputId": "27c5474e-fe32-4ab4-f50b-fbcc8561689a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mentorship program offers a comprehensive learning experience through a monthly subscription model, with a fee of $X per month.\n",
            "Spanning Y months, the total cost of the program is approximately $X * Y.\n",
            "This program covers a wide array of topics, including fundamentals, essential libraries/tools, data analysis, SQL for analysis, mathematics for learning, algorithms, practical implementation, operations and deployment, and case studies.\n",
            "For those interested in the detailed syllabus, it is available via a provided link.\n",
            "While the curriculum does not include advanced topics, it ensures a thorough understanding of the core concepts.\n",
            "All live sessions are recorded, allowing participants to catch up on any missed content at their convenience.\n",
            "The schedule for these sessions is organized month-by-month and accessible through a shared Google Sheet link.\n",
            "Each session typically lasts around 2 hours and is conducted in English, making it accessible to a broad audience.\n",
            "Participants are informed about upcoming classes through email notifications once they become paid users.\n",
            "This program is designed to be inclusive, welcoming individuals from non-technical backgrounds.\n",
            "Flexibility is a key feature, allowing participants to join at any point during the course.\n",
            "If joining mid-way, participants will have access to all previous lectures upon payment.\n",
            "Tasks provided during the course are meant for self-evaluation, with solutions supplied for personal assessment.\n",
            "Additionally, the program includes case studies to enhance practical understanding.\n",
            "For any queries, participants can reach out via the provided email address.\n",
            "Payments are to be made on the program's official website, following a monthly subscription model.\n",
            "While the entire amount cannot be paid upfront, the subscription is valid for 30 days from the payment date, ensuring participants do not need to wait for the start of a new month.\n",
            "A 7-day refund policy is in place for those who may reconsider their participation after making the payment.\n",
            "In case of payment issues due to location restrictions, the support team can be contacted through email.\n",
            "Post-registration, participants can watch paid videos as long as their subscription is active.\n",
            "Upon completing the full payment, access to the content extends until a specified date, beyond which a new subscription is required.\n",
            "Lifetime access is not provided due to the low course fee.\n",
            "For doubt resolution, a form available in the dashboard can be filled out, prompting the team to arrange a one-on-one doubt clearance session.\n",
            "Late joiners can still address past weeks' doubts by selecting the appropriate option in the doubt clearance form.\n",
            "The criteria for obtaining a certificate include paying the full fee and attempting all course assessments.\n",
            "For those joining late, a link to pay for the previous months' fees will be available in the dashboard after the current month's payment.\n",
            "Placement assistance is also part of the program, encompassing portfolio building sessions, soft skill training, and interactions with industry mentors.\n",
            "However, it is important to note that placement assistance does not equate to a placement guarantee.\n",
            "The focus is on equipping participants with the skills and knowledge needed to enhance their employability.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAKING DATASET"
      ],
      "metadata": {
        "id": "lUb7p1jwG4mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  print(tokenized_sentence)\n",
        "  print(len(tokenized_sentence))\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    print(i)\n",
        "    print(tokenized_sentence[:i+1])\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n",
        "    #[93, 1, 13]"
      ],
      "metadata": {
        "id": "XUHJ6KdHGz5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee1e07d-641a-4033-e169-ce9c2031c88c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2, 25, 7, 41, 86, 17]\n",
            "20\n",
            "1\n",
            "[1, 82]\n",
            "2\n",
            "[1, 82, 10]\n",
            "3\n",
            "[1, 82, 10, 83]\n",
            "4\n",
            "[1, 82, 10, 83, 2]\n",
            "5\n",
            "[1, 82, 10, 83, 2, 84]\n",
            "6\n",
            "[1, 82, 10, 83, 2, 84, 38]\n",
            "7\n",
            "[1, 82, 10, 83, 2, 84, 38, 85]\n",
            "8\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15]\n",
            "9\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2]\n",
            "10\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39]\n",
            "11\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13]\n",
            "12\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40]\n",
            "13\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16]\n",
            "14\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2]\n",
            "15\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2, 25]\n",
            "16\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2, 25, 7]\n",
            "17\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2, 25, 7, 41]\n",
            "18\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2, 25, 7, 41, 86]\n",
            "19\n",
            "[1, 82, 10, 83, 2, 84, 38, 85, 15, 2, 39, 13, 40, 16, 2, 25, 7, 41, 86, 17]\n",
            "[87, 42, 88, 1, 89, 90, 7, 1, 10, 4, 91, 41, 42]\n",
            "13\n",
            "1\n",
            "[87, 42]\n",
            "2\n",
            "[87, 42, 88]\n",
            "3\n",
            "[87, 42, 88, 1]\n",
            "4\n",
            "[87, 42, 88, 1, 89]\n",
            "5\n",
            "[87, 42, 88, 1, 89, 90]\n",
            "6\n",
            "[87, 42, 88, 1, 89, 90, 7]\n",
            "7\n",
            "[87, 42, 88, 1, 89, 90, 7, 1]\n",
            "8\n",
            "[87, 42, 88, 1, 89, 90, 7, 1, 10]\n",
            "9\n",
            "[87, 42, 88, 1, 89, 90, 7, 1, 10, 4]\n",
            "10\n",
            "[87, 42, 88, 1, 89, 90, 7, 1, 10, 4, 91]\n",
            "11\n",
            "[87, 42, 88, 1, 89, 90, 7, 1, 10, 4, 91, 41]\n",
            "12\n",
            "[87, 42, 88, 1, 89, 90, 7, 1, 10, 4, 91, 41, 42]\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105, 8, 106, 8, 26, 47]\n",
            "30\n",
            "1\n",
            "[43, 10]\n",
            "2\n",
            "[43, 10, 92]\n",
            "3\n",
            "[43, 10, 92, 2]\n",
            "4\n",
            "[43, 10, 92, 2, 93]\n",
            "5\n",
            "[43, 10, 92, 2, 93, 94]\n",
            "6\n",
            "[43, 10, 92, 2, 93, 94, 7]\n",
            "7\n",
            "[43, 10, 92, 2, 93, 94, 7, 44]\n",
            "8\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95]\n",
            "9\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96]\n",
            "10\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97]\n",
            "11\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98]\n",
            "12\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99]\n",
            "13\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100]\n",
            "14\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45]\n",
            "15\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101]\n",
            "16\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5]\n",
            "17\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45]\n",
            "18\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102]\n",
            "19\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5]\n",
            "20\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38]\n",
            "21\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103]\n",
            "22\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46]\n",
            "23\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104]\n",
            "24\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105]\n",
            "25\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105, 8]\n",
            "26\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105, 8, 106]\n",
            "27\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105, 8, 106, 8]\n",
            "28\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105, 8, 106, 8, 26]\n",
            "29\n",
            "[43, 10, 92, 2, 93, 94, 7, 44, 95, 96, 97, 98, 99, 100, 45, 101, 5, 45, 102, 5, 38, 103, 46, 104, 105, 8, 106, 8, 26, 47]\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4, 28, 48, 2, 19, 29]\n",
            "14\n",
            "1\n",
            "[5, 27]\n",
            "2\n",
            "[5, 27, 107]\n",
            "3\n",
            "[5, 27, 107, 9]\n",
            "4\n",
            "[5, 27, 107, 9, 1]\n",
            "5\n",
            "[5, 27, 107, 9, 1, 108]\n",
            "6\n",
            "[5, 27, 107, 9, 1, 108, 109]\n",
            "7\n",
            "[5, 27, 107, 9, 1, 108, 109, 18]\n",
            "8\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4]\n",
            "9\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4, 28]\n",
            "10\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4, 28, 48]\n",
            "11\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4, 28, 48, 2]\n",
            "12\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4, 28, 48, 2, 19]\n",
            "13\n",
            "[5, 27, 107, 9, 1, 108, 109, 18, 4, 28, 48, 2, 19, 29]\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113, 52, 7, 1, 114, 115]\n",
            "17\n",
            "1\n",
            "[49, 1]\n",
            "2\n",
            "[49, 1, 110]\n",
            "3\n",
            "[49, 1, 110, 50]\n",
            "4\n",
            "[49, 1, 110, 50, 20]\n",
            "5\n",
            "[49, 1, 110, 50, 20, 51]\n",
            "6\n",
            "[49, 1, 110, 50, 20, 51, 111]\n",
            "7\n",
            "[49, 1, 110, 50, 20, 51, 111, 44]\n",
            "8\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18]\n",
            "9\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112]\n",
            "10\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2]\n",
            "11\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113]\n",
            "12\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113, 52]\n",
            "13\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113, 52, 7]\n",
            "14\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113, 52, 7, 1]\n",
            "15\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113, 52, 7, 1, 114]\n",
            "16\n",
            "[49, 1, 110, 50, 20, 51, 111, 44, 18, 112, 2, 113, 52, 7, 1, 114, 115]\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32, 120, 54, 55, 23, 121]\n",
            "17\n",
            "1\n",
            "[30, 116]\n",
            "2\n",
            "[30, 116, 31]\n",
            "3\n",
            "[30, 116, 31, 21]\n",
            "4\n",
            "[30, 116, 31, 21, 117]\n",
            "5\n",
            "[30, 116, 31, 21, 117, 53]\n",
            "6\n",
            "[30, 116, 31, 21, 117, 53, 6]\n",
            "7\n",
            "[30, 116, 31, 21, 117, 53, 6, 3]\n",
            "8\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118]\n",
            "9\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119]\n",
            "10\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22]\n",
            "11\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32]\n",
            "12\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32, 120]\n",
            "13\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32, 120, 54]\n",
            "14\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32, 120, 54, 55]\n",
            "15\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32, 120, 54, 55, 23]\n",
            "16\n",
            "[30, 116, 31, 21, 117, 53, 6, 3, 118, 119, 22, 32, 120, 54, 55, 23, 121]\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15, 2, 125, 126, 127, 29]\n",
            "18\n",
            "1\n",
            "[1, 122]\n",
            "2\n",
            "[1, 122, 5]\n",
            "3\n",
            "[1, 122, 5, 123]\n",
            "4\n",
            "[1, 122, 5, 123, 31]\n",
            "5\n",
            "[1, 122, 5, 123, 31, 4]\n",
            "6\n",
            "[1, 122, 5, 123, 31, 4, 124]\n",
            "7\n",
            "[1, 122, 5, 123, 31, 4, 124, 17]\n",
            "8\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56]\n",
            "9\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17]\n",
            "10\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8]\n",
            "11\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57]\n",
            "12\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15]\n",
            "13\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15, 2]\n",
            "14\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15, 2, 125]\n",
            "15\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15, 2, 125, 126]\n",
            "16\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15, 2, 125, 126, 127]\n",
            "17\n",
            "[1, 122, 5, 123, 31, 4, 124, 17, 56, 17, 8, 57, 15, 2, 125, 126, 127, 29]\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18, 57, 3, 2, 136, 137]\n",
            "19\n",
            "1\n",
            "[128, 58]\n",
            "2\n",
            "[128, 58, 129]\n",
            "3\n",
            "[128, 58, 129, 130]\n",
            "4\n",
            "[128, 58, 129, 130, 131]\n",
            "5\n",
            "[128, 58, 129, 130, 131, 132]\n",
            "6\n",
            "[128, 58, 129, 130, 131, 132, 133]\n",
            "7\n",
            "[128, 58, 129, 130, 131, 132, 133, 8]\n",
            "8\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4]\n",
            "9\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134]\n",
            "10\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9]\n",
            "11\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135]\n",
            "12\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59]\n",
            "13\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18]\n",
            "14\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18, 57]\n",
            "15\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18, 57, 3]\n",
            "16\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18, 57, 3, 2]\n",
            "17\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18, 57, 3, 2, 136]\n",
            "18\n",
            "[128, 58, 129, 130, 131, 132, 133, 8, 4, 134, 9, 135, 59, 18, 57, 3, 2, 136, 137]\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142, 143, 144, 145, 34, 146]\n",
            "14\n",
            "1\n",
            "[6, 21]\n",
            "2\n",
            "[6, 21, 138]\n",
            "3\n",
            "[6, 21, 138, 139]\n",
            "4\n",
            "[6, 21, 138, 139, 140]\n",
            "5\n",
            "[6, 21, 138, 139, 140, 141]\n",
            "6\n",
            "[6, 21, 138, 139, 140, 141, 15]\n",
            "7\n",
            "[6, 21, 138, 139, 140, 141, 15, 33]\n",
            "8\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142]\n",
            "9\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142, 143]\n",
            "10\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142, 143, 144]\n",
            "11\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142, 143, 144, 145]\n",
            "12\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142, 143, 144, 145, 34]\n",
            "13\n",
            "[6, 21, 138, 139, 140, 141, 15, 33, 142, 143, 144, 145, 34, 146]\n",
            "[43, 10, 4, 147, 3, 11, 148, 149, 150, 60, 151, 152, 153]\n",
            "13\n",
            "1\n",
            "[43, 10]\n",
            "2\n",
            "[43, 10, 4]\n",
            "3\n",
            "[43, 10, 4, 147]\n",
            "4\n",
            "[43, 10, 4, 147, 3]\n",
            "5\n",
            "[43, 10, 4, 147, 3, 11]\n",
            "6\n",
            "[43, 10, 4, 147, 3, 11, 148]\n",
            "7\n",
            "[43, 10, 4, 147, 3, 11, 148, 149]\n",
            "8\n",
            "[43, 10, 4, 147, 3, 11, 148, 149, 150]\n",
            "9\n",
            "[43, 10, 4, 147, 3, 11, 148, 149, 150, 60]\n",
            "10\n",
            "[43, 10, 4, 147, 3, 11, 148, 149, 150, 60, 151]\n",
            "11\n",
            "[43, 10, 4, 147, 3, 11, 148, 149, 150, 60, 151, 152]\n",
            "12\n",
            "[43, 10, 4, 147, 3, 11, 148, 149, 150, 60, 151, 152, 153]\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55, 32, 158, 61, 1, 24]\n",
            "15\n",
            "1\n",
            "[154, 4]\n",
            "2\n",
            "[154, 4, 2]\n",
            "3\n",
            "[154, 4, 2, 155]\n",
            "4\n",
            "[154, 4, 2, 155, 156]\n",
            "5\n",
            "[154, 4, 2, 155, 156, 53]\n",
            "6\n",
            "[154, 4, 2, 155, 156, 53, 6]\n",
            "7\n",
            "[154, 4, 2, 155, 156, 53, 6, 3]\n",
            "8\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157]\n",
            "9\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55]\n",
            "10\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55, 32]\n",
            "11\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55, 32, 158]\n",
            "12\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55, 32, 158, 61]\n",
            "13\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55, 32, 158, 61, 1]\n",
            "14\n",
            "[154, 4, 2, 155, 156, 53, 6, 3, 157, 55, 32, 158, 61, 1, 24]\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3, 30, 64, 163, 65, 12]\n",
            "14\n",
            "1\n",
            "[159, 62]\n",
            "2\n",
            "[159, 62, 160]\n",
            "3\n",
            "[159, 62, 160, 161]\n",
            "4\n",
            "[159, 62, 160, 161, 6]\n",
            "5\n",
            "[159, 62, 160, 161, 6, 63]\n",
            "6\n",
            "[159, 62, 160, 161, 6, 63, 162]\n",
            "7\n",
            "[159, 62, 160, 161, 6, 63, 162, 35]\n",
            "8\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3]\n",
            "9\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3, 30]\n",
            "10\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3, 30, 64]\n",
            "11\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3, 30, 64, 163]\n",
            "12\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3, 30, 64, 163, 65]\n",
            "13\n",
            "[159, 62, 160, 161, 6, 63, 162, 35, 3, 30, 64, 163, 65, 12]\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16, 168, 169, 5, 170, 171]\n",
            "16\n",
            "1\n",
            "[164, 19]\n",
            "2\n",
            "[164, 19, 61]\n",
            "3\n",
            "[164, 19, 61, 1]\n",
            "4\n",
            "[164, 19, 61, 1, 24]\n",
            "5\n",
            "[164, 19, 61, 1, 24, 21]\n",
            "6\n",
            "[164, 19, 61, 1, 24, 21, 165]\n",
            "7\n",
            "[164, 19, 61, 1, 24, 21, 165, 5]\n",
            "8\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166]\n",
            "9\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167]\n",
            "10\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16]\n",
            "11\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16, 168]\n",
            "12\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16, 168, 169]\n",
            "13\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16, 168, 169, 5]\n",
            "14\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16, 168, 169, 5, 170]\n",
            "15\n",
            "[164, 19, 61, 1, 24, 21, 165, 5, 166, 167, 16, 168, 169, 5, 170, 171]\n",
            "[172, 1, 10, 173, 26, 47, 3, 66, 46, 52]\n",
            "10\n",
            "1\n",
            "[172, 1]\n",
            "2\n",
            "[172, 1, 10]\n",
            "3\n",
            "[172, 1, 10, 173]\n",
            "4\n",
            "[172, 1, 10, 173, 26]\n",
            "5\n",
            "[172, 1, 10, 173, 26, 47]\n",
            "6\n",
            "[172, 1, 10, 173, 26, 47, 3]\n",
            "7\n",
            "[172, 1, 10, 173, 26, 47, 3, 66]\n",
            "8\n",
            "[172, 1, 10, 173, 26, 47, 3, 66, 46]\n",
            "9\n",
            "[172, 1, 10, 173, 26, 47, 3, 66, 46, 52]\n",
            "[5, 32, 174, 6, 14, 175, 67, 48, 1, 19, 33, 68]\n",
            "12\n",
            "1\n",
            "[5, 32]\n",
            "2\n",
            "[5, 32, 174]\n",
            "3\n",
            "[5, 32, 174, 6]\n",
            "4\n",
            "[5, 32, 174, 6, 14]\n",
            "5\n",
            "[5, 32, 174, 6, 14, 175]\n",
            "6\n",
            "[5, 32, 174, 6, 14, 175, 67]\n",
            "7\n",
            "[5, 32, 174, 6, 14, 175, 67, 48]\n",
            "8\n",
            "[5, 32, 174, 6, 14, 175, 67, 48, 1]\n",
            "9\n",
            "[5, 32, 174, 6, 14, 175, 67, 48, 1, 19]\n",
            "10\n",
            "[5, 32, 174, 6, 14, 175, 67, 48, 1, 19, 33]\n",
            "11\n",
            "[5, 32, 174, 6, 14, 175, 67, 48, 1, 19, 33, 68]\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180, 181, 2, 39, 13, 40]\n",
            "15\n",
            "1\n",
            "[176, 21]\n",
            "2\n",
            "[176, 21, 3]\n",
            "3\n",
            "[176, 21, 3, 11]\n",
            "4\n",
            "[176, 21, 3, 11, 177]\n",
            "5\n",
            "[176, 21, 3, 11, 177, 22]\n",
            "6\n",
            "[176, 21, 3, 11, 177, 22, 1]\n",
            "7\n",
            "[176, 21, 3, 11, 177, 22, 1, 178]\n",
            "8\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179]\n",
            "9\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180]\n",
            "10\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180, 181]\n",
            "11\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180, 181, 2]\n",
            "12\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180, 181, 2, 39]\n",
            "13\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180, 181, 2, 39, 13]\n",
            "14\n",
            "[176, 21, 3, 11, 177, 22, 1, 178, 179, 180, 181, 2, 39, 13, 40]\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1, 193, 7, 2, 70, 17]\n",
            "33\n",
            "1\n",
            "[49, 1]\n",
            "2\n",
            "[49, 1, 182]\n",
            "3\n",
            "[49, 1, 182, 183]\n",
            "4\n",
            "[49, 1, 182, 183, 184]\n",
            "5\n",
            "[49, 1, 182, 183, 184, 11]\n",
            "6\n",
            "[49, 1, 182, 183, 184, 11, 34]\n",
            "7\n",
            "[49, 1, 182, 183, 184, 11, 34, 185]\n",
            "8\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1]\n",
            "9\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13]\n",
            "10\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4]\n",
            "11\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186]\n",
            "12\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5]\n",
            "13\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187]\n",
            "14\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188]\n",
            "15\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60]\n",
            "16\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1]\n",
            "17\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12]\n",
            "18\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69]\n",
            "19\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189]\n",
            "20\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6]\n",
            "21\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190]\n",
            "22\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20]\n",
            "23\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191]\n",
            "24\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3]\n",
            "25\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192]\n",
            "26\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5]\n",
            "27\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1]\n",
            "28\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1, 193]\n",
            "29\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1, 193, 7]\n",
            "30\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1, 193, 7, 2]\n",
            "31\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1, 193, 7, 2, 70]\n",
            "32\n",
            "[49, 1, 182, 183, 184, 11, 34, 185, 1, 13, 4, 186, 5, 187, 188, 60, 1, 12, 69, 189, 6, 190, 20, 191, 3, 192, 5, 1, 193, 7, 2, 70, 17]\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23, 202, 71, 59, 1, 12]\n",
            "19\n",
            "1\n",
            "[2, 194]\n",
            "2\n",
            "[2, 194, 195]\n",
            "3\n",
            "[2, 194, 195, 196]\n",
            "4\n",
            "[2, 194, 195, 196, 197]\n",
            "5\n",
            "[2, 194, 195, 196, 197, 4]\n",
            "6\n",
            "[2, 194, 195, 196, 197, 4, 9]\n",
            "7\n",
            "[2, 194, 195, 196, 197, 4, 9, 198]\n",
            "8\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5]\n",
            "9\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27]\n",
            "10\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199]\n",
            "11\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200]\n",
            "12\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201]\n",
            "13\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23]\n",
            "14\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23, 202]\n",
            "15\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23, 202, 71]\n",
            "16\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23, 202, 71, 59]\n",
            "17\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23, 202, 71, 59, 1]\n",
            "18\n",
            "[2, 194, 195, 196, 197, 4, 9, 198, 5, 27, 199, 200, 201, 23, 202, 71, 59, 1, 12]\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73, 14, 11, 207, 15, 33]\n",
            "17\n",
            "1\n",
            "[9, 26]\n",
            "2\n",
            "[9, 26, 7]\n",
            "3\n",
            "[9, 26, 7, 12]\n",
            "4\n",
            "[9, 26, 7, 12, 203]\n",
            "5\n",
            "[9, 26, 7, 12, 203, 72]\n",
            "6\n",
            "[9, 26, 7, 12, 203, 72, 3]\n",
            "7\n",
            "[9, 26, 7, 12, 203, 72, 3, 204]\n",
            "8\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205]\n",
            "9\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1]\n",
            "10\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206]\n",
            "11\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73]\n",
            "12\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73, 14]\n",
            "13\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73, 14, 11]\n",
            "14\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73, 14, 11, 207]\n",
            "15\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73, 14, 11, 207, 15]\n",
            "16\n",
            "[9, 26, 7, 12, 203, 72, 3, 204, 205, 1, 206, 73, 14, 11, 207, 15, 33]\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212, 74, 23, 13, 4, 213]\n",
            "14\n",
            "1\n",
            "[208, 209]\n",
            "2\n",
            "[208, 209, 6]\n",
            "3\n",
            "[208, 209, 6, 14]\n",
            "4\n",
            "[208, 209, 6, 14, 210]\n",
            "5\n",
            "[208, 209, 6, 14, 210, 34]\n",
            "6\n",
            "[208, 209, 6, 14, 210, 34, 211]\n",
            "7\n",
            "[208, 209, 6, 14, 210, 34, 211, 74]\n",
            "8\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212]\n",
            "9\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212, 74]\n",
            "10\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212, 74, 23]\n",
            "11\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212, 74, 23, 13]\n",
            "12\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212, 74, 23, 13, 4]\n",
            "13\n",
            "[208, 209, 6, 14, 210, 34, 211, 74, 212, 74, 23, 13, 4, 213]\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219, 2, 70, 13, 4, 220]\n",
            "21\n",
            "1\n",
            "[65, 214]\n",
            "2\n",
            "[65, 214, 1]\n",
            "3\n",
            "[65, 214, 1, 75]\n",
            "4\n",
            "[65, 214, 1, 75, 12]\n",
            "5\n",
            "[65, 214, 1, 75, 12, 35]\n",
            "6\n",
            "[65, 214, 1, 75, 12, 35, 3]\n",
            "7\n",
            "[65, 214, 1, 75, 12, 35, 3, 1]\n",
            "8\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54]\n",
            "9\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215]\n",
            "10\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216]\n",
            "11\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2]\n",
            "12\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217]\n",
            "13\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69]\n",
            "14\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218]\n",
            "15\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219]\n",
            "16\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219, 2]\n",
            "17\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219, 2, 70]\n",
            "18\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219, 2, 70, 13]\n",
            "19\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219, 2, 70, 13, 4]\n",
            "20\n",
            "[65, 214, 1, 75, 12, 35, 3, 1, 54, 215, 216, 2, 217, 69, 218, 219, 2, 70, 13, 4, 220]\n",
            "[221, 35, 4, 20, 19, 72, 3, 1, 222, 24, 25]\n",
            "11\n",
            "1\n",
            "[221, 35]\n",
            "2\n",
            "[221, 35, 4]\n",
            "3\n",
            "[221, 35, 4, 20]\n",
            "4\n",
            "[221, 35, 4, 20, 19]\n",
            "5\n",
            "[221, 35, 4, 20, 19, 72]\n",
            "6\n",
            "[221, 35, 4, 20, 19, 72, 3]\n",
            "7\n",
            "[221, 35, 4, 20, 19, 72, 3, 1]\n",
            "8\n",
            "[221, 35, 4, 20, 19, 72, 3, 1, 222]\n",
            "9\n",
            "[221, 35, 4, 20, 19, 72, 3, 1, 222, 24]\n",
            "10\n",
            "[221, 35, 4, 20, 19, 72, 3, 1, 222, 24, 25]\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78, 22, 78, 36, 79, 58]\n",
            "25\n",
            "1\n",
            "[5, 36]\n",
            "2\n",
            "[5, 36, 223]\n",
            "3\n",
            "[5, 36, 223, 2]\n",
            "4\n",
            "[5, 36, 223, 2, 76]\n",
            "5\n",
            "[5, 36, 223, 2, 76, 28]\n",
            "6\n",
            "[5, 36, 223, 2, 76, 28, 9]\n",
            "7\n",
            "[5, 36, 223, 2, 76, 28, 9, 1]\n",
            "8\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77]\n",
            "9\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14]\n",
            "10\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11]\n",
            "11\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224]\n",
            "12\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67]\n",
            "13\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225]\n",
            "14\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1]\n",
            "15\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73]\n",
            "16\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3]\n",
            "17\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226]\n",
            "18\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2]\n",
            "19\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78]\n",
            "20\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78, 22]\n",
            "21\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78, 22, 78]\n",
            "22\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78, 22, 78, 36]\n",
            "23\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78, 22, 78, 36, 79]\n",
            "24\n",
            "[5, 36, 223, 2, 76, 28, 9, 1, 77, 14, 11, 224, 67, 225, 1, 73, 3, 226, 2, 78, 22, 78, 36, 79, 58]\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234, 9, 1, 36, 79, 76]\n",
            "18\n",
            "1\n",
            "[80, 227]\n",
            "2\n",
            "[80, 227, 14]\n",
            "3\n",
            "[80, 227, 14, 228]\n",
            "4\n",
            "[80, 227, 14, 228, 68]\n",
            "5\n",
            "[80, 227, 14, 228, 68, 229]\n",
            "6\n",
            "[80, 227, 14, 228, 68, 229, 230]\n",
            "7\n",
            "[80, 227, 14, 228, 68, 229, 230, 231]\n",
            "8\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56]\n",
            "9\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232]\n",
            "10\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1]\n",
            "11\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233]\n",
            "12\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234]\n",
            "13\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234, 9]\n",
            "14\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234, 9, 1]\n",
            "15\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234, 9, 1, 36]\n",
            "16\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234, 9, 1, 36, 79]\n",
            "17\n",
            "[80, 227, 14, 228, 68, 229, 230, 231, 56, 232, 1, 233, 234, 9, 1, 36, 79, 76]\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25, 8, 239, 30, 24, 240]\n",
            "16\n",
            "1\n",
            "[1, 235]\n",
            "2\n",
            "[1, 235, 5]\n",
            "3\n",
            "[1, 235, 5, 236]\n",
            "4\n",
            "[1, 235, 5, 236, 2]\n",
            "5\n",
            "[1, 235, 5, 236, 2, 237]\n",
            "6\n",
            "[1, 235, 5, 236, 2, 237, 51]\n",
            "7\n",
            "[1, 235, 5, 236, 2, 237, 51, 238]\n",
            "8\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1]\n",
            "9\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75]\n",
            "10\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25]\n",
            "11\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25, 8]\n",
            "12\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25, 8, 239]\n",
            "13\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25, 8, 239, 30]\n",
            "14\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25, 8, 239, 30, 24]\n",
            "15\n",
            "[1, 235, 5, 236, 2, 237, 51, 238, 1, 75, 25, 8, 239, 30, 24, 240]\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77, 71, 1, 244, 245, 12]\n",
            "24\n",
            "1\n",
            "[5, 27]\n",
            "2\n",
            "[5, 27, 62]\n",
            "3\n",
            "[5, 27, 62, 80]\n",
            "4\n",
            "[5, 27, 62, 80, 2]\n",
            "5\n",
            "[5, 27, 62, 80, 2, 29]\n",
            "6\n",
            "[5, 27, 62, 80, 2, 29, 3]\n",
            "7\n",
            "[5, 27, 62, 80, 2, 29, 3, 241]\n",
            "8\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5]\n",
            "9\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1]\n",
            "10\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64]\n",
            "11\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242]\n",
            "12\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243]\n",
            "13\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63]\n",
            "14\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11]\n",
            "15\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28]\n",
            "16\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9]\n",
            "17\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1]\n",
            "18\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77]\n",
            "19\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77, 71]\n",
            "20\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77, 71, 1]\n",
            "21\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77, 71, 1, 244]\n",
            "22\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77, 71, 1, 244, 245]\n",
            "23\n",
            "[5, 27, 62, 80, 2, 29, 3, 241, 5, 1, 64, 242, 243, 63, 11, 28, 9, 1, 77, 71, 1, 244, 245, 12]\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253, 8, 254, 16, 255, 256]\n",
            "20\n",
            "1\n",
            "[37, 81]\n",
            "2\n",
            "[37, 81, 4]\n",
            "3\n",
            "[37, 81, 4, 246]\n",
            "4\n",
            "[37, 81, 4, 246, 247]\n",
            "5\n",
            "[37, 81, 4, 246, 247, 7]\n",
            "6\n",
            "[37, 81, 4, 246, 247, 7, 1]\n",
            "7\n",
            "[37, 81, 4, 246, 247, 7, 1, 10]\n",
            "8\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248]\n",
            "9\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249]\n",
            "10\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250]\n",
            "11\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31]\n",
            "12\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251]\n",
            "13\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252]\n",
            "14\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253]\n",
            "15\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253, 8]\n",
            "16\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253, 8, 254]\n",
            "17\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253, 8, 254, 16]\n",
            "18\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253, 8, 254, 16, 255]\n",
            "19\n",
            "[37, 81, 4, 246, 247, 7, 1, 10, 248, 249, 250, 31, 251, 252, 253, 8, 254, 16, 255, 256]\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20, 261, 3, 2, 37, 262]\n",
            "16\n",
            "1\n",
            "[257, 18]\n",
            "2\n",
            "[257, 18, 4]\n",
            "3\n",
            "[257, 18, 4, 258]\n",
            "4\n",
            "[257, 18, 4, 258, 3]\n",
            "5\n",
            "[257, 18, 4, 258, 3, 259]\n",
            "6\n",
            "[257, 18, 4, 258, 3, 259, 260]\n",
            "7\n",
            "[257, 18, 4, 258, 3, 259, 260, 37]\n",
            "8\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81]\n",
            "9\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50]\n",
            "10\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20]\n",
            "11\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20, 261]\n",
            "12\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20, 261, 3]\n",
            "13\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20, 261, 3, 2]\n",
            "14\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20, 261, 3, 2, 37]\n",
            "15\n",
            "[257, 18, 4, 258, 3, 259, 260, 37, 81, 50, 20, 261, 3, 2, 37, 262]\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266, 267, 3, 66, 23, 268]\n",
            "16\n",
            "1\n",
            "[1, 263]\n",
            "2\n",
            "[1, 263, 4]\n",
            "3\n",
            "[1, 263, 4, 22]\n",
            "4\n",
            "[1, 263, 4, 22, 264]\n",
            "5\n",
            "[1, 263, 4, 22, 264, 6]\n",
            "6\n",
            "[1, 263, 4, 22, 264, 6, 16]\n",
            "7\n",
            "[1, 263, 4, 22, 264, 6, 16, 1]\n",
            "8\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265]\n",
            "9\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8]\n",
            "10\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266]\n",
            "11\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266, 267]\n",
            "12\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266, 267, 3]\n",
            "13\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266, 267, 3, 66]\n",
            "14\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266, 267, 3, 66, 23]\n",
            "15\n",
            "[1, 263, 4, 22, 264, 6, 16, 1, 265, 8, 266, 267, 3, 66, 23, 268]\n",
            "[]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kpd3Xzty1Xc",
        "outputId": "5f7d6fec-1bfc-47eb-d8fc-5cc6525f230c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we need the sequence which has max length since we have to do padding\n",
        "#so all vectors get in equal length\n",
        "max_len= max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "5twaiSmdHFJI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aio0JjqQIKLO",
        "outputId": "40efca5e-4a51-4915-8cb8-242cb78a8eba"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "5IlDjxeXHgaE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc1Y76e7Hpg4",
        "outputId": "2382f2d2-2ccf-4700-c426-fb06a765d528"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   1,  82],\n",
              "       [  0,   0,   0, ...,   1,  82,  10],\n",
              "       [  0,   0,   0, ...,  82,  10,  83],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 267,   3,  66],\n",
              "       [  0,   0,   0, ...,   3,  66,  23],\n",
              "       [  0,   0,   0, ...,  66,  23, 268]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to get [1 2] from [1 2 3]\n",
        "X = padded_input_sequences[:,:-1]\n"
      ],
      "metadata": {
        "id": "9KvI_llMHvSr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to get [3] from [1 2 3]\n",
        "y= padded_input_sequences[:,-1]\n"
      ],
      "metadata": {
        "id": "Qd_utsRqHyWo"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyc6UQwgIA0Q",
        "outputId": "8ce16742-800a-42ba-fc12-e695b2febbda"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(478, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yjG6OlSITuc",
        "outputId": "e10c0946-5bd4-4fb9-e761-8993d1248990"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(478,)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding 1 -->[001] , 2-->[010], 3-->[011]\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=479) # because it starts from 0 for one hot encoding so to encode 282 we need 283 also"
      ],
      "metadata": {
        "id": "8p-LMTA0IqWw"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRPEdZuZKBkg",
        "outputId": "273c607a-23d4-4e0d-e4b0-dc4c9bf341b8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(478, 479)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "GS4aN2J0I-r-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(479, 100, input_length=32))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(479, activation='softmax'))"
      ],
      "metadata": {
        "id": "Ft5X-ZQ2JBSF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BhJiNs00Jkj8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QubE6DvYJlHm",
        "outputId": "9d589387-b17b-4827-c372-9c116450819d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 32, 100)           47900     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 479)               72329     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 270829 (1.03 MB)\n",
            "Trainable params: 270829 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRwasum4JmaD",
        "outputId": "d097bdb7-8906-4bea-e721-3a3144bfdd04"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 4s 71ms/step - loss: 6.0915 - accuracy: 0.0377\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 5.5680 - accuracy: 0.0439\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 5.2822 - accuracy: 0.0481\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 5.2129 - accuracy: 0.0607\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 5.1838 - accuracy: 0.0607\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 5.1637 - accuracy: 0.0607\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 5.1529 - accuracy: 0.0607\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 5.1403 - accuracy: 0.0607\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 5.1254 - accuracy: 0.0607\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 2s 112ms/step - loss: 5.1020 - accuracy: 0.0607\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 5.0726 - accuracy: 0.0607\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 5.0260 - accuracy: 0.0607\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 4.9675 - accuracy: 0.0669\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 4.8743 - accuracy: 0.0858\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 4.7653 - accuracy: 0.1025\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 4.6454 - accuracy: 0.1192\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 4.5128 - accuracy: 0.1464\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 4.3665 - accuracy: 0.1506\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 4.2214 - accuracy: 0.1695\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 1s 81ms/step - loss: 4.0732 - accuracy: 0.1715\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 3.9341 - accuracy: 0.1904\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 2s 112ms/step - loss: 3.7846 - accuracy: 0.2134\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 3.6507 - accuracy: 0.2406\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 3.5133 - accuracy: 0.2615\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 3.3799 - accuracy: 0.2887\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 3.2531 - accuracy: 0.3054\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 3.1152 - accuracy: 0.3452\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 2.9987 - accuracy: 0.3452\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 2.8817 - accuracy: 0.3724\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 2.7472 - accuracy: 0.4142\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 2.6262 - accuracy: 0.4435\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 1s 98ms/step - loss: 2.5103 - accuracy: 0.4707\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 2.3961 - accuracy: 0.5188\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 2.2824 - accuracy: 0.5377\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 2.1731 - accuracy: 0.5962\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 2.0668 - accuracy: 0.6360\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 1.9612 - accuracy: 0.6757\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 1.8639 - accuracy: 0.7071\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 1.7699 - accuracy: 0.7469\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 1.6783 - accuracy: 0.7803\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 1.5849 - accuracy: 0.8054\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 1.5063 - accuracy: 0.8305\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 1s 95ms/step - loss: 1.4232 - accuracy: 0.8368\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 1.3452 - accuracy: 0.8640\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 1s 96ms/step - loss: 1.2729 - accuracy: 0.8682\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 1.2078 - accuracy: 0.8954\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 1.1386 - accuracy: 0.9017\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 1.0800 - accuracy: 0.9163\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 1.0230 - accuracy: 0.9226\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.9593 - accuracy: 0.9289\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.9072 - accuracy: 0.9331\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.8553 - accuracy: 0.9477\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.8093 - accuracy: 0.9477\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.7681 - accuracy: 0.9498\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 2s 122ms/step - loss: 0.7295 - accuracy: 0.9582\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 2s 121ms/step - loss: 0.6912 - accuracy: 0.9582\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.6538 - accuracy: 0.9603\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.6195 - accuracy: 0.9582\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.5879 - accuracy: 0.9644\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.5610 - accuracy: 0.9728\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.5330 - accuracy: 0.9686\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.5052 - accuracy: 0.9749\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.4819 - accuracy: 0.9707\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.4628 - accuracy: 0.9749\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.4395 - accuracy: 0.9749\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 1s 76ms/step - loss: 0.4198 - accuracy: 0.9770\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.4016 - accuracy: 0.9791\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 2s 106ms/step - loss: 0.3849 - accuracy: 0.9812\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.3685 - accuracy: 0.9812\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.3537 - accuracy: 0.9812\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.3390 - accuracy: 0.9791\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.3264 - accuracy: 0.9770\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.3126 - accuracy: 0.9770\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.3016 - accuracy: 0.9791\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2895 - accuracy: 0.9812\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.2784 - accuracy: 0.9791\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2696 - accuracy: 0.9791\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 2s 111ms/step - loss: 0.2615 - accuracy: 0.9791\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.2520 - accuracy: 0.9791\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.2419 - accuracy: 0.9791\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 2s 120ms/step - loss: 0.2350 - accuracy: 0.9791\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.2274 - accuracy: 0.9791\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2204 - accuracy: 0.9791\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2146 - accuracy: 0.9833\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.2072 - accuracy: 0.9791\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.2009 - accuracy: 0.9791\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 0.1946 - accuracy: 0.9791\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 2s 111ms/step - loss: 0.1895 - accuracy: 0.9812\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.1845 - accuracy: 0.9791\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.1807 - accuracy: 0.9812\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.1755 - accuracy: 0.9791\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.1700 - accuracy: 0.9812\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.1653 - accuracy: 0.9791\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.1614 - accuracy: 0.9812\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.1573 - accuracy: 0.9833\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.1547 - accuracy: 0.9770\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.1502 - accuracy: 0.9812\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.1474 - accuracy: 0.9812\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 1s 79ms/step - loss: 0.1439 - accuracy: 0.9791\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.1408 - accuracy: 0.9791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a7b68616b30>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "text = \"what is the fee\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=32, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2qj2DrrJoZa",
        "outputId": "37928f84-a526-41d6-e5cf-f1273e51afb8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 467ms/step\n",
            "what is the fee participants\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "what is the fee participants can\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "what is the fee participants can watch\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "what is the fee participants can watch paid\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "what is the fee participants can watch paid videos\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "what is the fee participants can watch paid videos as\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "what is the fee participants can watch paid videos as their\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "what is the fee participants can watch paid videos as their subscription\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "what is the fee participants can watch paid videos as their subscription is\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "what is the fee participants can watch paid videos as their subscription is active\n"
          ]
        }
      ]
    }
  ]
}